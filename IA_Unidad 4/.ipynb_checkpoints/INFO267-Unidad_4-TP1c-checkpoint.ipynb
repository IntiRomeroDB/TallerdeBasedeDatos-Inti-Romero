{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Entrenar y evaluar una red neuronal convolucional para resolver un problema de clasificación de imágenes</center>\n",
    "\n",
    "<div style=\"background-color: #fdebd0 \">\n",
    "<b>Este TP tiene 3 objetivos:</b><br>\n",
    "- Describir conceptos vinculados al entrenamiento y uso de <i>ConvNets</i> para la clasificación de imágenes<br>\n",
    "- Familiarizarse con la librería PyTorch<br>\n",
    "- Reproducir un protocolo para entrenar una red neuronal convolucional y clasificar imágenes.</div>\n",
    "\n",
    "\n",
    "PyTorch es una librería de aprendizaje automático de código abierto para Python, desarrollada principalmente por el grupo de investigación de inteligencia artificial de Facebook. Dentro de PyTorch, el paquete <code>torchvision</code> consiste en conjuntos de datos populares, arquitecturas de modelos y transformaciones de imágenes comunes para la visión artificial.\n",
    "\n",
    "En la primera parte del trabajo práctico, utilizaremos el conjunto de datos CIFAR10 disponible en <code>torchvision</code>.  Este dataset sirve para aprender a resolver un problema de clasificación con 10 clases: 'avión', 'automóvil', 'pájaro', 'gato', 'ciervo', 'perro', 'rana', 'caballo', 'barco', 'camión'. Las imágenes en CIFAR-10 son de tamaño 3x32x32, es decir, imágenes en color de 3 canales de 32x32 píxeles de tamaño: https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "\n",
    "El código está basado en el tutorial de PyTorch siguiente: https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
    "\n",
    "<img src=\"cifar10.png\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para resolver el problema de clasificación de imágenes, seguiremos los siguientes pasos:\n",
    "\n",
    "- Cargar y normalizar los conjuntos de datos de entrenamiento y pruebas utilizando CIFAR10.\n",
    "- Configurar una red neuronal de convolución\n",
    "- Definir una función de pérdida\n",
    "- Optimizar la red sobre los datos de entrenamiento\n",
    "- Probar el rendimiento de la red con los datos de test\n",
    "\n",
    "Por cada paso, se solicita responder a una serie de preguntas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Cargar y normalizar el dataset CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#el paquete torch contiene estructuras de datos para tensores multidimensionales y se definen operaciones\n",
    "#matemáticas sobre estos. Además, proporciona muchas utilidades para la serialización eficiente de tensores y tipos\n",
    "#arbitrarios, y otras utilidades útiles.\n",
    "import torch\n",
    "#torchvision: libreria de imagenes\n",
    "import torchvision\n",
    "#TRANSFORMACIONES DE IMAGENES COMUNES\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "#La salida del conjunto de datos \"torchvision\" son imagenes del tipo PILImage de rango [0, 1]. \n",
    "\n",
    "\n",
    "#Compose: Compone varias transformaciones juntas. \n",
    "# Define una función que realizará varias transformaciones de forma simultanea\n",
    "#ToTensor(): Convierte una imagen PIL o un numpy.ndarray a un tensor.\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# trainset: (image, target) donde target es un indice de la clase de target.\n",
    "# root:      Directorio en mi computadora del servidor Anaconda donde el data set será guardado si no existe.\n",
    "# train:     Si es Verdadero, crea un conjunto de datos desde el conjunto de entrenamiento, de lo contrario crea desde el conjunto de prueba.\n",
    "# download:  Si es verdadero, descarga el conjunto de datos de Internet y lo coloca en el directorio raíz. \n",
    "#            Si el conjunto de datos ya está descargado, no se vuelve a descargar.\n",
    "# transform: Una función / transformación que toma una imagen PIL y devuelve una versión transformada.\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "#### Data loader: Combina un conjunto de datos y una muestra, y proporciona iteradores de proceso único o \n",
    "#                    múltiple sobre el conjunto de datos. \n",
    "\n",
    "# trainset: Conjunto de datos desde donde se cargaran los datos.\n",
    "# batch_size: Cuántas muestras por lote cargar. \n",
    "# shuffle: Configúrelo en Verdadero para que los datos se reorganicen en cada época.\n",
    "# num_workers: How many subprocesses to use for data loading. 0 means that the data will be loaded in the main process.\n",
    "\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #fdebd0 \">\n",
    "<b>Preguntas</b><br>\n",
    "<b>1) ¿Cuál es el tamaño del dataset de entrenamiento y del dataset de test? (Imprimir el resultado con la función <code>print</code>)</b><br>\n",
    "Como se observa abajo, el tamaño del dataset de entrenamiento es de 50000 datos y el tamaño del dataset de test es de 10000 datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset CIFAR10\n",
      "    Number of datapoints: 50000\n",
      "    Split: train\n",
      "    Root Location: ./data\n",
      "    Transforms (if any): Compose(\n",
      "                             ToTensor()\n",
      "                             Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
      "                         )\n",
      "    Target Transforms (if any): None\n"
     ]
    }
   ],
   "source": [
    "print(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset CIFAR10\n",
      "    Number of datapoints: 10000\n",
      "    Split: test\n",
      "    Root Location: ./data\n",
      "    Transforms (if any): Compose(\n",
      "                             ToTensor()\n",
      "                             Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
      "                         )\n",
      "    Target Transforms (if any): None\n"
     ]
    }
   ],
   "source": [
    "print(testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #fdebd0 \">\n",
    "<b>2) ¿Por qué el parametro <code>shuffle</code> se configura \"True\" para el dataset de entrenamiento y \"False\" para el dataset de test? </b><br>\n",
    "    \n",
    "Este parametro se configura True para que el sub conjunto de datos que será tomado del dataset sea \"barajado\", es decir el orden de las imagenes sea cambiado de forma aleatoria. Y se configura false para que el sub conjunto de datos que será tomado del dataset NO sea \"barajado\".<br> \n",
    "<b>¿De qué sirve este parametro?</b><br>\n",
    "Sirve para que al entrenar el modelo el orden en el que se encuentran las imagenes no introdusca algún sesgo al modelo.\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B>El código siguiente permite mostrar imagenes aleatorias del dataset de entrenamiento y su etiqueta real:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  cat  ship   dog   car\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "    \n",
    "def imagesFromBatches(iterator,quantity):\n",
    "    dataiter = iter(iterator)\n",
    "    images, labels = dataiter.next()    \n",
    "    imshow(torchvision.utils.make_grid(images))\n",
    "    print(' '.join('%5s' % classes[labels[j]] for j in range(quantity)))\n",
    "    return (images,labels)\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configurar la CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 6, 28, 28]             456\n",
      "         MaxPool2d-2            [-1, 6, 14, 14]               0\n",
      "            Conv2d-3           [-1, 16, 10, 10]           2,416\n",
      "         MaxPool2d-4             [-1, 16, 5, 5]               0\n",
      "            Linear-5                  [-1, 120]          48,120\n",
      "            Linear-6                   [-1, 84]          10,164\n",
      "            Linear-7                   [-1, 10]             850\n",
      "================================================================\n",
      "Total params: 62,006\n",
      "Trainable params: 62,006\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.06\n",
      "Params size (MB): 0.24\n",
      "Estimated Total Size (MB): 0.31\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "# Importa funciones de convolución\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "# nn.Module: Clase base para todos los módulos de red neuronal. Sus modelos también deben subclasificar esta clase.\n",
    "#### ESTA CREANDO UN OBJETO QUE SERA LA RED NEURONAL\n",
    "class Net(nn.Module):\n",
    "    #### Módulo de red neuronal?? - ¿ESTA CREANDO EL CONSTRUCTOR DEL OBJETO\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        #### ESTAS SON FUNCIONES PRIVADAS DEL OBJETO\n",
    "        \n",
    "        # CONVOLUCION: Transformar la imagen para representar sus características relevantes y eliminar la información irrelevante\n",
    "        # para resolver el problema de clasificación.\n",
    "        \n",
    "        # nn.Conv2d(in_channels, out_channels, kernel_size): Aplica una convolución 2D sobre una señal de entrada\n",
    "        #                                                    compuesta de varios planos de entrada.\n",
    "        #    in_channels: Número de canales en la imagen de entrada.\n",
    "        #    out_channels: Número de canales producidos por la convolución. Número de filtros.\n",
    "        ####    kernel_size: Tamaño del núcleo que está convolucionando. -- TAMAÑO DEL FILTRO EN ESTA CASO MATRIZ 5X5\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        \n",
    "        # POOLING: Reducir el tamaño de las imágenes, acelerar los tiempos de cálculo y mejorar la detección de las características\n",
    "        # nn.MaxPool2d(kernel_size, stride=None): Aplica un max pooling 2D sobre una señal de entrada compuesta por varios planos de entrada.\n",
    "        #            kernel_size: El tamaño de la ventana sobre la cual se tomara un máximo. El tamaño del filtro.\n",
    "        #            stride: El paso de la ventana.\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        \n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        \n",
    "        #Fully-connected layers o MultiLayer Perceptron - Ultimas capas de la CNN o red neuronal convolucional\n",
    "        # Algoritmo Perceptrón (Rosemblatt, 1962) resuelve problema de clasificación binaria.\n",
    "        # nn.Linear(in_features, out_features): Aplica una transformación lineal a los datos entrantes: y = xA^T+b\n",
    "        #         in_features: Tamaño de cada muestra de entrada.: metodos de clasficiacion\n",
    "        #         out_features: Tamaño de cada muestra de salida.\n",
    "        #         \n",
    "        \n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "\n",
    "summary(net,(3,32,32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #fdebd0 \">\n",
    "<b>Preguntas</b><br>\n",
    "<B>1) ¿Cuántas capas tiene esta ConvNet?</B><br>\n",
    "    7 capas <br>\n",
    "<B>2) Explicar los parametros de cada capa.</B>  <br>\n",
    "nn.Conv2d(in_channels, out_channels, kernel_size):\n",
    "<BR>\n",
    "- in_channels: Número de canales en la imagen de entrada.\n",
    "<BR>\n",
    "- out_channels: Número de filtros<BR>\n",
    "- kernel_size: Tamaño de los filtros. Por ejemplo: si es 5, el tamaño de los filtros será de 5x5. \n",
    "<br>\n",
    "nn.MaxPool2d(kernel_size, stride=None):<br>\n",
    "kernel_size: El tamaño de la ventana sobre la cual se tomara un máximo. El tamaño del filtro.<br>\n",
    "stride: El paso del filtro.<br>\n",
    "nn.Linear(in_features, out_features):<br> \n",
    "in_features: Cantidad de entradas que tendrá cada uno de los métodos de clasificación de esta capa.\n",
    "    <br> \n",
    "out_features: Cantidad de métodos de clasificación de esta capa.<br>\n",
    "    \n",
    "<B>¿Cuántos filtros se utilizan en las capas de convolución?</B><BR>\n",
    "Son en total 24 filtros. En la primera capa de convolución se utilizan 6 filtros. En la primera capa de pooling se utiliza 1 filtro.\n",
    "En la segunda capa de convolución se utilizan 16 filtros y en la segunda capa de pooling de utiliza 1 filtro.<br>\n",
    "\n",
    "<B>¿Cuál es el tamaño de los filtros?  </B>      \n",
    "<br>\n",
    "Todos los filtros en las capas de convolución son matrices de 5x5. Los filtros en las capas de pooling son de 2x2.   \n",
    "\n",
    "<B>3) ¿Cuál es la diferencia entre la función <code>init</code> y <code>forward</code>?</B><br>\n",
    "La función <code>init</code> es el constructor de la clase Net, inicializando sus funciones, mientras que la\n",
    "función <code>forward</code> es una funcion que utiliza las funciones definidas en <code>init</code> para realizar el proceso de clasificación de imágenes, aplicando capas tras capa de la red neuronal a las imagenes de entrada. En resumen, define todo el proceso que tiene que seguir la imagen para pasar por la red neuronal.<br>\n",
    " \n",
    "<B>4) ¿De qué sirve la función view()? Explicar sus parametros.</B><br>\n",
    "    En este caso transforma un tensor multidimensional a un tensor de 1 dimensión. El primer parámetro de entrada de la función \"view\" define el nuevo número de\n",
    "    filas que tendrá el tensor. El segundo parámetro define el nuevo número de columnas que tendrá el tensor. Si no se está seguro de la cantidad de filas que se quiere en el nuevo tensor, pero si se sabe la cantidad de columnas que se desea, entonces se puede colocar en el primer parámetro un \"-1\" y en el segundo parámetro se puede colocal el número de columnas deseado y de forma automática se esablecerá el número de filas dependiendo del número de columnas puesto.<BR>\n",
    "<B>5) ¿Cuántos paramétros en total se tiene que aprender con esta ConvNet?</B> <br>\n",
    "    62.006<br>\n",
    "<B>6) ¿Por qué se utiliza la función <code>conv2d</code> aunque tenemos imagenes con 3 canales?</B><BR>\n",
    "Porque el filtro tiene la misma dimesión que la imagen de entrada.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Entrenar la CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# torch.optim: Es un paquete que implementa varios algoritmos de optimización.\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()#calcula quien tiene el menor \"gradiente\", cual punto alrededor es el minimo\n",
    "\n",
    "# optim.SGD(params, lr=<required parameter>, momentum=0, dampening=0, weight_decay=0, nesterov=False): Implementa stochastic gradient descent \n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "#algoritmo para actualizar los parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.141\n",
      "[1,  4000] loss: 1.808\n",
      "[1,  6000] loss: 1.658\n",
      "[1,  8000] loss: 1.552\n",
      "[1, 10000] loss: 1.493\n",
      "[1, 12000] loss: 1.459\n",
      "[2,  2000] loss: 1.387\n",
      "[2,  4000] loss: 1.362\n",
      "[2,  6000] loss: 1.320\n",
      "[2,  8000] loss: 1.322\n",
      "[2, 10000] loss: 1.290\n",
      "[2, 12000] loss: 1.280\n",
      "[3,  2000] loss: 1.204\n",
      "[3,  4000] loss: 1.226\n",
      "[3,  6000] loss: 1.192\n",
      "[3,  8000] loss: 1.186\n",
      "[3, 10000] loss: 1.199\n",
      "[3, 12000] loss: 1.174\n",
      "[4,  2000] loss: 1.110\n",
      "[4,  4000] loss: 1.129\n",
      "[4,  6000] loss: 1.094\n",
      "[4,  8000] loss: 1.105\n",
      "[4, 10000] loss: 1.116\n",
      "[4, 12000] loss: 1.096\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(4):  # loop over the dataset multiple times\n",
    "#itera y trata de encontrar las lmejores solucions para este sistema\n",
    "#hacer el proceso varias veces, empezando desde un punto distinto\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ver la video: https://www.youtube.com/watch?v=ErfnhcEV1O8 - A Short Introduction to Entropy, Cross-Entropy and KL-Divergence\n",
    "\n",
    "- Leer: http://ruder.io/optimizing-gradient-descent/index.html - An overview of gradient descent optimization algorithm\n",
    "\n",
    "<div style=\"background-color: #fdebd0 \">\n",
    "<b>Preguntas</b><br>\n",
    "<b>1) ¿Qué hace la función <code>CrossEntropyLoss</code>? </b><br>\n",
    "Nos dice cuan acertadas son las predicciones de nuestro modelo en comparación al conjunto de datos de entrenamiento.<BR>\n",
    "<b>Qué devuelve?</b><br>\n",
    "Un número que mienstras más se acerca a cero, significa que los resultados del modelo obtendio se parecen más a los resultados mostrados por los datos del dataset de entrenamiento.<br>\n",
    "<b>¿Con qué otra función se podría reemplazar <code>CrossEntropy</code>?</b><br>\n",
    "Multi class SVM Loss: Esta es una de las funciones de pérdida comunes utilizadas en Machine Learning.<br>\n",
    "<b>2) ¿Cuál es la diferencia principal entre los métodos de optimización Gradient Descent, Stochastic Gradient Descent y Mini-Batch Gradient Descent?</b>\n",
    "<br>\n",
    "Pudiendo calcular el gradiente de la función de pérdida, se denomina Gradient Descent al proceso de evaluar repetidamente el gradiente y luego realizar una actualización de los parámetros del modelo, pero es lento y no puede tratar conjuntos de datos que no puedan ser cargados en su totalidad en la memoria ram.<br>\n",
    "\n",
    "Una forma de explicar la diferencia entre estos métodos es decir que el método Gradient Descent es un igual a un modelo Mini-Batch con un mini-batch del tamaño del conjunto total de datos de entrenamiento. De la misma forma podriamos decir que un modelo Stochastic Gradient Descent es igual a un modelo Mini-Batch con un mini-batch de tamaño 1. Y finalemente el modelo Mini-Batch se espera sea un concenso entre SGD y GD con un mini.batch ni muy grande ni muy pequeño. En resumen la diferencia entre estos métodos es la cantidad de muestras que utilizan del dataset de entrenamiento para obtener los parámetros del modelo.<br>\n",
    " \n",
    "<b>3) ¿En nuestro ejemplo, qué método utilizamos?</b><BR>\n",
    "Mini-Batch Gradient Descent<BR>\n",
    "<b>¿En qué parte del código se podría cambiar el tamaño del batch?</b><br> \n",
    "Cuando se define la función \"trainloader\".<br>\n",
    "<b>4) ¿Qué metafora podemos utilizar para entender la idea del parametro <code>momentum</code>?</b><br>\n",
    "Es como el efecto de la gravedad sobre una balón de futbol sobre una colina. A medida que va bajando la colina el balón comienza a acelerar. Así mismo a medida que el modelo va iterando y buscando su camino hacia un mínimo, si el modelo comeinza a \"rebotar\" de un lado a otro de modo que no avanza con mucha velocidad hacia el mínimo, el parámetro de momentum le permite dejar de \"rebotar\" y dirigirse más rápido hacia el mínimo.<br>\n",
    "<b>5) ¿Podría ser útil aumentar el número de epoch? ¿Por qué? De qué sirve este parametro?</b><br>\n",
    "Si, pues al ir cambiando de epoch se toma como punto inicial uno diferente al tomado anteriormente, lo que evita caer en la misma solución local todo el tiempo. Este parámetro sirve para definir el número de veces que pasaremos por todo nuestro dataset de entrenamiento entrenando nuestro modelo.<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluar la CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tomamos 4 ejemplos del dataset de test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  cat  ship  ship plane\n"
     ]
    }
   ],
   "source": [
    "BatchSize=4\n",
    "\n",
    "images,labels= imagesFromBatches(testloader,BatchSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clasificamos estas 4 imágenes con nuestra CNN: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:    cat  ship  ship plane\n"
     ]
    }
   ],
   "source": [
    "outputs = net(images)\n",
    "\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #fdebd0 \">\n",
    "<b>Pregunta</b><br>\n",
    "<B>1) ¿Cuál es el rendimiento del modelo entrenado sobre estos primeros ejemplos?</B><BR>\n",
    "EL RENDIMIENTO ES DE 100%, pues predijo todos los ejemplos de forma correcta.<br>\n",
    "</div>\n",
    "\n",
    "Calculamos el rendimiento de nuestra CNN sobre todos los datos del training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 58 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Miramos el rendimiento de la CNN calculando su exactitud según cada etiqueta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of plane : 66 %\n",
      "Accuracy of   car : 78 %\n",
      "Accuracy of  bird : 44 %\n",
      "Accuracy of   cat : 35 %\n",
      "Accuracy of  deer : 40 %\n",
      "Accuracy of   dog : 41 %\n",
      "Accuracy of  frog : 84 %\n",
      "Accuracy of horse : 63 %\n",
      "Accuracy of  ship : 79 %\n",
      "Accuracy of truck : 55 %\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #fdebd0 \">\n",
    "<b>Preguntas:</b><br>\n",
    "<b>1) ¿Qué paramétros podrían modificar para tratar de mejorar el rendimiento de la CNN?</b> <br>\n",
    "Se podría modificar el tamaño del mini-batch y la tasa de aprendizaje.<BR>\n",
    "\n",
    "<b>2) ¿Cómo se llama la arquitectura de CNN que hemos utilizado? (ver slides del curso y https://medium.com/@sidereal/cnns-architectures-lenet-alexnet-vgg-googlenet-resnet-and-more-666091488df5 y https://adeshpande3.github.io/The-9-Deep-Learning-Papers-You-Need-To-Know-About.html)</b><br>\n",
    "LeNet-5<br>\n",
    "<b>3) ¿Qué pasa si tratan de agregar más filtros en la segunda capa de convolución?</b> <br>\n",
    "Tendríamos que modificar la definición del input de la primera capa MLP. Además tendríamos que modificar también la definición de la función \"view\". A continuación se presenta un ejemplo en que se agregan 4 filtros más a la segunda capa de convolución:\n",
    "    \n",
    "<code>self.conv2 = nn.Conv2d(6, 16, 5)      ->        self.conv2 = nn.Conv2d(6, 20, 5)</code><br> \n",
    "<code>self.fc1 = nn.Linear(16 * 5 * 5, 120)       ->       self.fc1 = nn.Linear(20 * 5 * 5, 120) </code><br> \n",
    "<code>x = x.view(-1, 16 * 5 * 5)      ->       x = x.view(-1, 20 * 5 * 5) </code>  <br> \n",
    "<b>4) ¿Qué pasa si trata de agregar una tercera capa de convolución y pooling? </b><br>\n",
    "Aparece un error de la función \"view\".\n",
    "    \n",
    "<b>5) ¿En la literatura, qué arquitecturas CNN permiten obtener mejores rendimiento que la arquitectura LeNet-5?  </b><br>\n",
    "AlexNet(7): 15.3% Top-5 error rate on ILSVRC.<br>\n",
    "ZFNet: 14.8% Top-5 error rate on ILSVRC.<br>\n",
    "GoogLeNet(19): 6.67% Top-5 error rate on ILSVRC.<br>\n",
    "VGG Net(16): 7.3% Top-5 error rate on ILSVRC.<br>\n",
    "ResNet(152): 3.6% Top-5 error rate on ILSVRC.\n",
    "<br>\n",
    "<b>Cuál es el limite de estas arquitecturas?</b><br>\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #fdebd0 \">\n",
    "<b>T.P</b><br>\n",
    "Optimizar una CNN para resolver el problema asociado al dataset Fashion-MNIST (https://pytorch.org/docs/stable/torchvision/datasets.html#fashion-mnist). <br>\n",
    "\n",
    "1) ¿La arquitectura LeNet-5 es mejor que Random Forest? Comparar el rendimiento obtenido con lo obtenido por el algoritmo RandomForest (con 50 estimadores).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#el paquete torch contiene estructuras de datos para tensores multidimensionales y se definen operaciones\n",
    "#matemáticas sobre estos. Además, proporciona muchas utilidades para la serialización eficiente de tensores y tipos\n",
    "#arbitrarios, y otras utilidades útiles.\n",
    "import torch\n",
    "#torchvision: libreria de imagenes\n",
    "import torchvision\n",
    "#TRANSFORMACIONES DE IMAGENES COMUNES\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "#La salida del conjunto de datos \"torchvision\" son imagenes del tipo PILImage de rango [0, 1]. \n",
    "\n",
    "\n",
    "#Compose: Compone varias transformaciones juntas. \n",
    "# Define una función que realizará varias transformaciones de forma simultanea\n",
    "#ToTensor(): Convierte una imagen PIL o un numpy.ndarray a un tensor.\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# trainset: (image, target) donde target es un indice de la clase de target.\n",
    "# root:      Directorio en mi computadora del servidor Anaconda donde el data set será guardado si no existe.\n",
    "# train:     Si es Verdadero, crea un conjunto de datos desde el conjunto de entrenamiento, de lo contrario crea desde el conjunto de prueba.\n",
    "# download:  Si es verdadero, descarga el conjunto de datos de Internet y lo coloca en el directorio raíz. \n",
    "#            Si el conjunto de datos ya está descargado, no se vuelve a descargar.\n",
    "# transform: Una función / transformación que toma una imagen PIL y devuelve una versión transformada.\n",
    "\n",
    "trainset = torchvision.datasets.FashionMNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "#### Data loader: Combina un conjunto de datos y una muestra, y proporciona iteradores de proceso único o \n",
    "#                    múltiple sobre el conjunto de datos. \n",
    "\n",
    "# trainset: Conjunto de datos desde donde se cargaran los datos.\n",
    "# batch_size: Cuántas muestras por lote cargar. \n",
    "# shuffle: Configúrelo en Verdadero para que los datos se reorganicen en cada época.\n",
    "# num_workers: How many subprocesses to use for data loading. 0 means that the data will be loaded in the main process.\n",
    "\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " frog  deer  bird  deer\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "    \n",
    "def imagesFromBatches(iterator,quantity):\n",
    "    dataiter = iter(iterator)\n",
    "    images, labels = dataiter.next()    \n",
    "    imshow(torchvision.utils.make_grid(images))\n",
    "    print(' '.join('%5s' % classes[labels[j]] for j in range(quantity)))\n",
    "    return (images,labels)\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 6, 24, 24]             156\n",
      "         MaxPool2d-2            [-1, 6, 12, 12]               0\n",
      "            Conv2d-3             [-1, 16, 8, 8]           2,416\n",
      "         MaxPool2d-4             [-1, 16, 4, 4]               0\n",
      "            Linear-5                  [-1, 120]          61,560\n",
      "            Linear-6                   [-1, 84]          10,164\n",
      "            Linear-7                   [-1, 10]             850\n",
      "================================================================\n",
      "Total params: 75,146\n",
      "Trainable params: 75,146\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.04\n",
      "Params size (MB): 0.29\n",
      "Estimated Total Size (MB): 0.33\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "# Importa funciones de convolución\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "# nn.Module: Clase base para todos los módulos de red neuronal. Sus modelos también deben subclasificar esta clase.\n",
    "#### ESTA CREANDO UN OBJETO QUE SERA LA RED NEURONAL\n",
    "class Net(nn.Module):\n",
    "    #### Módulo de red neuronal?? - ¿ESTA CREANDO EL CONSTRUCTOR DEL OBJETO\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        #### ESTAS SON FUNCIONES PRIVADAS DEL OBJETO\n",
    "        \n",
    "        # CONVOLUCION: Transformar la imagen para representar sus características relevantes y eliminar la información irrelevante\n",
    "        # para resolver el problema de clasificación.\n",
    "        \n",
    "        # nn.Conv2d(in_channels, out_channels, kernel_size): Aplica una convolución 2D sobre una señal de entrada\n",
    "        #                                                    compuesta de varios planos de entrada.\n",
    "        #    in_channels: Número de canales en la imagen de entrada.\n",
    "        #    out_channels: Número de canales producidos por la convolución. Número de filtros.\n",
    "        ####    kernel_size: Tamaño del núcleo que está convolucionando. -- TAMAÑO DEL FILTRO EN ESTA CASO MATRIZ 5X5\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        \n",
    "        # POOLING: Reducir el tamaño de las imágenes, acelerar los tiempos de cálculo y mejorar la detección de las características\n",
    "        # nn.MaxPool2d(kernel_size, stride=None): Aplica un max pooling 2D sobre una señal de entrada compuesta por varios planos de entrada.\n",
    "        #            kernel_size: El tamaño de la ventana sobre la cual se tomara un máximo. El tamaño del filtro.\n",
    "        #            stride: El paso de la ventana.\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        \n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        \n",
    "        #Fully-connected layers o MultiLayer Perceptron - Ultimas capas de la CNN o red neuronal convolucional\n",
    "        # Algoritmo Perceptrón (Rosemblatt, 1962) resuelve problema de clasificación binaria.\n",
    "        # nn.Linear(in_features, out_features): Aplica una transformación lineal a los datos entrantes: y = xA^T+b\n",
    "        #         in_features: Tamaño de cada muestra de entrada.: metodos de clasficiacion\n",
    "        #         out_features: Tamaño de cada muestra de salida.\n",
    "        #         \n",
    "        \n",
    "        self.fc1 = nn.Linear(512, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 512)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "\n",
    "summary(net,(1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.optim: Es un paquete que implementa varios algoritmos de optimización.\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()#calcula quien tiene el menor \"gradiente\", cual punto alrededor es el minimo\n",
    "\n",
    "# optim.SGD(params, lr=<required parameter>, momentum=0, dampening=0, weight_decay=0, nesterov=False): Implementa stochastic gradient descent \n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "#algoritmo para actualizar los parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected input batch_size (2) to match target batch_size (4).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-d13deca0f4c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# forward + backward + optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    902\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0;32m--> 904\u001b[0;31m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[1;32m    905\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   1968\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1969\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1970\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   1786\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1787\u001b[0m         raise ValueError('Expected input batch_size ({}) to match target batch_size ({}).'\n\u001b[0;32m-> 1788\u001b[0;31m                          .format(input.size(0), target.size(0)))\n\u001b[0m\u001b[1;32m   1789\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1790\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected input batch_size (2) to match target batch_size (4)."
     ]
    }
   ],
   "source": [
    "for epoch in range(4):  # loop over the dataset multiple times\n",
    "#itera y trata de encontrar las lmejores solucions para este sistema\n",
    "#hacer el proceso varias veces, empezando desde un punto distinto\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
